"""
ë²¡í„° ìŠ¤í† ì–´
ChromaDBë¥¼ ì‚¬ìš©í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import os
import uuid
import chromadb
from chromadb.config import Settings as ChromaSettings
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer

from core.config import get_settings
from core.logging.config import get_logger

logger = get_logger(__name__)


class VectorStore:
    """ë²¡í„° ìŠ¤í† ì–´"""

    def __init__(self):
        self.settings = get_settings()
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.document_count = 0

        # ì´ˆê¸°í™”
        self._initialize_chromadb()
        self._initialize_embedding_model()

    def _initialize_chromadb(self):
        """ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”§ ChromaDB ì´ˆê¸°í™” ì¤‘...")

            # ChromaDB ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
            db_path = os.path.abspath(self.settings.VECTOR_DB_PATH)
            os.makedirs(db_path, exist_ok=True)

            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            self.client = chromadb.PersistentClient(
                path=db_path, settings=ChromaSettings(anonymized_telemetry=False, allow_reset=True)
            )

            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            try:
                self.collection = self.client.get_collection(name=self.settings.COLLECTION_NAME)
                self.document_count = self.collection.count()
                logger.info(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {self.settings.COLLECTION_NAME} ({self.document_count}ê°œ ë¬¸ì„œ)")
            except Exception:
                # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                self.collection = self.client.create_collection(
                    name=self.settings.COLLECTION_NAME, metadata={"description": "Law Mate ë²•ë¥  ë¬¸ì„œ ì»¬ë ‰ì…˜"}
                )
                logger.info(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.settings.COLLECTION_NAME}")

        except Exception as e:
            logger.error(f"âŒ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise

    def _initialize_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.settings.EMBEDDING_MODEL}")

            self.embedding_model = SentenceTransformer(self.settings.EMBEDDING_MODEL)

            logger.info("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            # ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±
            try:
                logger.warning("ğŸ”„ ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ë¡œ í´ë°± ì‹œë„...")
                self.embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
                logger.info("âœ… ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as fallback_error:
                logger.error(f"âŒ ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {str(fallback_error)}")
                raise

    async def add_documents(self, documents: List[Dict[str, Any]]) -> bool:
        """ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì¶”ê°€"""
        try:
            if not documents:
                logger.warning("âš ï¸ ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return True

            logger.info(f"ğŸ“Š ë²¡í„° DBì— {len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì¤‘...")

            # ë¬¸ì„œ ë°ì´í„° ì¤€ë¹„
            ids = []
            contents = []
            metadatas = []
            embeddings = []

            for doc in documents:
                # ê³ ìœ  ID ìƒì„±
                doc_id = doc.get("id", str(uuid.uuid4()))
                ids.append(doc_id)

                # ë¬¸ì„œ ë‚´ìš©
                content = doc.get("content", "")
                contents.append(content)

                # ë©”íƒ€ë°ì´í„°
                metadata = doc.get("metadata", {})
                # ChromaDBëŠ” ë¬¸ìì—´ê³¼ ìˆ«ìë§Œ ì§€ì›í•˜ë¯€ë¡œ ë³€í™˜
                clean_metadata = self._clean_metadata(metadata)
                clean_metadata["source"] = doc.get("source", "unknown")
                metadatas.append(clean_metadata)

                # ì„ë² ë”© ìƒì„±
                if content:
                    embedding = self.embedding_model.encode(content).tolist()
                    embeddings.append(embedding)
                else:
                    logger.warning(f"âš ï¸ ë¹ˆ ë¬¸ì„œ ë‚´ìš©: {doc_id}")
                    embeddings.append([0.0] * self.embedding_model.get_sentence_embedding_dimension())

            # ChromaDBì— ì¶”ê°€
            self.collection.add(ids=ids, documents=contents, metadatas=metadatas, embeddings=embeddings)

            self.document_count = self.collection.count()
            logger.info(f"âœ… ë²¡í„° DB ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ: ì´ {self.document_count}ê°œ ë¬¸ì„œ")
            return True

        except Exception as e:
            logger.error(f"âŒ ë²¡í„° DB ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
            return False

    async def search_similar(
        self, query: str, top_k: int = 5, similarity_threshold: float = 0.0
    ) -> List[Dict[str, Any]]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        try:
            logger.debug(f"ğŸ” ë²¡í„° ê²€ìƒ‰: '{query[:50]}...' (top_k={top_k})")

            if not query.strip():
                logger.warning("âš ï¸ ë¹ˆ ê²€ìƒ‰ ì¿¼ë¦¬")
                return []

            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.encode(query).tolist()

            # ChromaDB ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=min(top_k, self.document_count) if self.document_count > 0 else top_k,
                include=["documents", "metadatas", "distances"],
            )

            # ê²°ê³¼ ë³€í™˜
            search_results = []
            if results["documents"] and results["documents"][0]:
                for i, (doc, metadata, distance) in enumerate(
                    zip(results["documents"][0], results["metadatas"][0], results["distances"][0])
                ):
                    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ)
                    similarity = 1.0 / (1.0 + distance)

                    if similarity >= similarity_threshold:
                        search_results.append(
                            {
                                "content": doc,
                                "source": metadata.get("source", "unknown"),
                                "metadata": metadata,
                                "similarity_score": similarity,
                                "distance": distance,
                                "rank": i + 1,
                            }
                        )

            logger.debug(f"âœ… ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results

        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    async def delete_documents(self, document_ids: List[str]) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        try:
            logger.info(f"ğŸ—‘ï¸ {len(document_ids)}ê°œ ë¬¸ì„œ ì‚­ì œ ì¤‘...")

            # ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ IDë§Œ í•„í„°ë§
            existing_ids = []
            for doc_id in document_ids:
                try:
                    result = self.collection.get(ids=[doc_id])
                    if result["ids"]:
                        existing_ids.append(doc_id)
                except Exception:
                    logger.warning(f"âš ï¸ ë¬¸ì„œ ID ì—†ìŒ: {doc_id}")

            if existing_ids:
                self.collection.delete(ids=existing_ids)
                self.document_count = self.collection.count()
                logger.info(f"âœ… {len(existing_ids)}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì‚­ì œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")

            return True

        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            return False

    async def clear_collection(self) -> bool:
        """ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ"""
        try:
            logger.warning("ğŸ—‘ï¸ ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ ì¤‘...")

            # ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
            self.client.delete_collection(name=self.settings.COLLECTION_NAME)
            self.collection = self.client.create_collection(
                name=self.settings.COLLECTION_NAME, metadata={"description": "Law Mate ë²•ë¥  ë¬¸ì„œ ì»¬ë ‰ì…˜"}
            )

            self.document_count = 0
            logger.info("âœ… ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"âŒ ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            return False

    async def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´"""
        try:
            stats = {
                "total_documents": self.document_count,
                "collection_name": self.settings.COLLECTION_NAME,
                "embedding_model": self.settings.EMBEDDING_MODEL,
                "db_path": self.settings.VECTOR_DB_PATH,
            }

            # ì¶”ê°€ í†µê³„ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                # ìƒ˜í”Œ ë¬¸ì„œ ì¡°íšŒë¡œ ë©”íƒ€ë°ì´í„° ë¶„ì„
                sample_results = self.collection.get(limit=10)
                if sample_results["metadatas"]:
                    sources = set()
                    for metadata in sample_results["metadatas"]:
                        if "source" in metadata:
                            sources.add(metadata["source"])
                    stats["unique_sources"] = len(sources)
                    stats["sample_sources"] = list(sources)[:5]
            except Exception:
                pass

            return stats

        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"total_documents": self.document_count, "error": str(e)}

    async def get_all_documents(self) -> List[Dict[str, Any]]:
        """
        ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ì„ ìœ„í•œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
        ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        try:
            logger.info(f"ğŸ“„ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì¤‘... (ì´ {self.document_count}ê°œ)")

            if self.document_count == 0:
                logger.warning("âš ï¸ ì¡°íšŒí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return []

            # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
            # ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ìœ„í•´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¡°íšŒ
            batch_size = 1000  # í•œ ë²ˆì— ì¡°íšŒí•  ë¬¸ì„œ ìˆ˜
            all_documents = []

            # ì „ì²´ ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì¡°íšŒ
            for offset in range(0, self.document_count, batch_size):
                try:
                    # í˜„ì¬ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
                    current_batch_size = min(batch_size, self.document_count - offset)

                    logger.debug(f"ğŸ“‹ ë°°ì¹˜ ì¡°íšŒ ì¤‘: {offset + 1} ~ {offset + current_batch_size}")

                    # ChromaDBì—ì„œ ë°°ì¹˜ ì¡°íšŒ
                    batch_results = self.collection.get(
                        limit=current_batch_size, offset=offset, include=["documents", "metadatas"]
                    )

                    # ê²°ê³¼ ì²˜ë¦¬
                    if batch_results["documents"]:
                        for i, (content, metadata) in enumerate(
                            zip(batch_results["documents"], batch_results["metadatas"])
                        ):
                            # ë¬¸ì„œ ë°ì´í„° êµ¬ì„± (IDëŠ” ìë™ ìƒì„±)
                            document = {
                                "id": f"doc_{offset + i}",  # ì„ì‹œ ID ìƒì„±
                                "content": content,
                                "source": metadata.get("source", "unknown"),
                                "metadata": metadata,
                            }
                            all_documents.append(document)

                    logger.debug(f"âœ… ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: {len(batch_results['documents'])}ê°œ ë¬¸ì„œ")

                except Exception as batch_error:
                    logger.error(f"âŒ ë°°ì¹˜ ì¡°íšŒ ì‹¤íŒ¨ (offset: {offset}): {str(batch_error)}")
                    # ë°°ì¹˜ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
                    continue

            logger.info(f"âœ… ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ: {len(all_documents)}ê°œ ë¬¸ì„œ")
            return all_documents

        except Exception as e:
            logger.error(f"âŒ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []

    async def get_documents_by_source(self, source: str) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • ì†ŒìŠ¤ì˜ ë¬¸ì„œë“¤ë§Œ ì¡°íšŒ
        íŠ¹ì • íŒŒì¼ì´ë‚˜ ì†ŒìŠ¤ì—ì„œ ì˜¨ ë¬¸ì„œë“¤ë§Œ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©
        """
        try:
            logger.info(f"ğŸ“„ ì†ŒìŠ¤ë³„ ë¬¸ì„œ ì¡°íšŒ: {source}")

            # ë©”íƒ€ë°ì´í„° í•„í„°ë§ìœ¼ë¡œ íŠ¹ì • ì†ŒìŠ¤ ë¬¸ì„œ ì¡°íšŒ
            results = self.collection.get(where={"source": source}, include=["documents", "metadatas"])

            documents = []
            if results["documents"]:
                for i, (content, metadata) in enumerate(zip(results["documents"], results["metadatas"])):
                    documents.append(
                        {
                            "id": f"source_{source}_{i}",  # ì„ì‹œ ID ìƒì„±
                            "content": content,
                            "source": metadata.get("source", "unknown"),
                            "metadata": metadata,
                        }
                    )

            logger.info(f"âœ… ì†ŒìŠ¤ë³„ ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
            return documents

        except Exception as e:
            logger.error(f"âŒ ì†ŒìŠ¤ë³„ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []

    async def get_documents_count_by_source(self) -> Dict[str, int]:
        """
        ì†ŒìŠ¤ë³„ ë¬¸ì„œ ê°œìˆ˜ í†µê³„
        ê° ì†ŒìŠ¤(íŒŒì¼)ë³„ë¡œ ëª‡ ê°œì˜ ë¬¸ì„œê°€ ìˆëŠ”ì§€ ì¡°íšŒ
        """
        try:
            logger.debug("ğŸ“Š ì†ŒìŠ¤ë³„ ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ ì¤‘...")

            # ëª¨ë“  ë©”íƒ€ë°ì´í„° ì¡°íšŒ
            results = self.collection.get(include=["metadatas"])

            # ì†ŒìŠ¤ë³„ ê°œìˆ˜ ê³„ì‚°
            source_counts = {}
            if results["metadatas"]:
                for metadata in results["metadatas"]:
                    source = metadata.get("source", "unknown")
                    source_counts[source] = source_counts.get(source, 0) + 1

            logger.debug(f"âœ… ì†ŒìŠ¤ë³„ ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ ì™„ë£Œ: {len(source_counts)}ê°œ ì†ŒìŠ¤")
            return source_counts

        except Exception as e:
            logger.error(f"âŒ ì†ŒìŠ¤ë³„ ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {}

    def _clean_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ChromaDB í˜¸í™˜ ë©”íƒ€ë°ì´í„°ë¡œ ë³€í™˜"""
        clean_metadata = {}

        for key, value in metadata.items():
            # ChromaDBëŠ” ë¬¸ìì—´ê³¼ ìˆ«ìë§Œ ì§€ì›
            if isinstance(value, (str, int, float, bool)):
                clean_metadata[key] = value
            elif isinstance(value, list):
                # ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                clean_metadata[key] = ", ".join(str(v) for v in value)
            elif isinstance(value, dict):
                # ë”•ì…”ë„ˆë¦¬ëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                import json

                clean_metadata[key] = json.dumps(value, ensure_ascii=False)
            else:
                # ê¸°íƒ€ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                clean_metadata[key] = str(value)

        return clean_metadata

    def get_document_count(self) -> int:
        """ë¬¸ì„œ ê°œìˆ˜ ë°˜í™˜"""
        return self.document_count

    async def health_check(self) -> Dict[str, Any]:
        """ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸"""
        try:
            # ê¸°ë³¸ ì •ë³´
            health_info = {
                "status": "healthy",
                "client_connected": self.client is not None,
                "collection_exists": self.collection is not None,
                "embedding_model_loaded": self.embedding_model is not None,
                "document_count": self.document_count,
            }

            # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            try:
                test_results = await self.search_similar("í…ŒìŠ¤íŠ¸", top_k=1)
                health_info["search_functional"] = True
                health_info["search_test_results"] = len(test_results)
            except Exception as e:
                health_info["search_functional"] = False
                health_info["search_error"] = str(e)

            return health_info

        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}
