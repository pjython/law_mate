"""
RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
RAG ì‹œìŠ¤í…œì˜ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì¡°ìœ¨í•˜ëŠ” ì¤‘ì•™ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
ì™„ì „í•œ LangChain íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import time
from typing import Dict, Any, List, Optional

from core.config import get_settings
from core.logging.config import get_logger
from services.document.processor import DocumentProcessor
from services.search.hybrid_search import HybridSearchService

# LangChain RAG ì„œë¹„ìŠ¤ë§Œ ì‚¬ìš©
from services.llm.langchain_rag_service import LangChainRAGService
from infrastructure.database.vector_store import VectorStore

# ë¶„ë¦¬ëœ RAG ì„œë¹„ìŠ¤ë“¤
from services.rag.response_formatter import ResponseFormatter
from services.rag.system_monitor import SystemMonitor

# ëŒ€í™” ê´€ë¦¬ëŠ” LangChain Memoryê°€ ì²˜ë¦¬

logger = get_logger(__name__)


class RAGOrchestrator:
    """
    RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    ì™„ì „í•œ LangChain íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì§ˆë¬¸ ë¶„ë¥˜ë¶€í„° ë‹µë³€ ìƒì„±ê¹Œì§€ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì¤‘...")

            self.settings = get_settings()

            # í•µì‹¬ ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.vector_store = VectorStore()
            self.document_processor = DocumentProcessor()
            self.langchain_rag_service = LangChainRAGService()
            self.search_service = HybridSearchService(self.vector_store)

            # ë¶„ë¦¬ëœ RAG ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™”
            self.response_formatter = ResponseFormatter()
            self.system_monitor = SystemMonitor()

            # ëŒ€í™” ê´€ë¦¬ëŠ” LangChain Memoryê°€ ìë™ ì²˜ë¦¬

            logger.info("âœ… RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            self.system_monitor.record_error(str(e), "initialization") if hasattr(self, "system_monitor") else None
            raise

    async def initialize(self) -> bool:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ“š RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

            # ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë²¡í„° ìŠ¤í† ì–´ëŠ” ìƒì„±ìì—ì„œ ì´ë¯¸ ì´ˆê¸°í™”ë¨)
            if hasattr(self.search_service, "initialize"):
                await self.search_service.initialize()

            # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„° ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
            document_count = self.vector_store.get_document_count()
            self.system_monitor.update_initialization_status(
                is_initialized=True, documents_loaded=document_count, search_index_built=True
            )

            logger.info("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
            self.system_monitor.log_system_info()

            return True

        except Exception as e:
            error_msg = f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self.system_monitor.record_error(error_msg, "initialization")
            return False

    async def process_query(
        self, user_query: str, user_id: Optional[str] = None, session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (ì™„ì „í•œ LangChain RAG íŒŒì´í”„ë¼ì¸)
        ì§ˆë¬¸ ë¶„ë¥˜ â†’ ë¬¸ì„œ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±ì´ í•˜ë‚˜ì˜ ì²´ì¸ìœ¼ë¡œ ì—°ê²°ë¨
        ëŒ€í™” ë§¥ë½ì€ LangChain Memoryê°€ ìë™ ê´€ë¦¬

        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            user_id: ì‚¬ìš©ì ID (ì„ íƒì‚¬í•­)
            session_id: ì„¸ì…˜ ID (ì„ íƒì‚¬í•­, ì—†ìœ¼ë©´ ìë™ ìƒì„±)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()

        try:
            logger.info(f"ğŸš€ LangChain íŒŒì´í”„ë¼ì¸ ì§ˆë¬¸ ì²˜ë¦¬: '{user_query}' (ì„¸ì…˜: {session_id})")

            # ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„± (UUID ê¸°ë°˜)
            if not session_id:
                import uuid

                session_id = str(uuid.uuid4())
                logger.debug(f"ğŸ†• ìƒˆ ì„¸ì…˜ ID ìƒì„±: {session_id}")

            # ì™„ì „í•œ LangChain RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Memory ìë™ ê´€ë¦¬)
            rag_result = await self.langchain_rag_service.process_query(query=user_query, session_id=session_id)

            processing_time = time.time() - start_time
            logger.info(f"âœ… LangChain íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            self.system_monitor.record_query_performance(processing_time, success=True)

            # ìµœì¢… ì‘ë‹µì— ì„¸ì…˜ ë° ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
            rag_result["session_id"] = session_id
            rag_result["processing_time"] = processing_time
            rag_result["pipeline_type"] = "langchain_full_rag"

            return rag_result

        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ {error_msg}")

            self.system_monitor.record_error(error_msg, "query_processing")
            self.system_monitor.record_query_performance(processing_time, success=False)

            return self.response_formatter.create_error_response(error_msg, "QUERY_PROCESSING_ERROR", processing_time)

    async def get_conversation_history(self, session_id: str) -> Dict[str, Any]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ (LangChain Memoryì—ì„œ)"""
        try:
            # LangChain Memoryì—ì„œ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
            memory_stats = self.langchain_rag_service.get_memory_stats(session_id)

            if memory_stats:
                return {
                    "success": True,
                    "session_id": session_id,
                    "messages": memory_stats.get("messages", []),
                    "total_messages": memory_stats.get("message_count", 0),
                    "context": {
                        "session_id": session_id,
                        "memory_type": memory_stats.get("memory_type", "ConversationBufferWindowMemory"),
                    },
                }
            else:
                return {"success": False, "error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "messages": [], "total_messages": 0, "context": {}}

        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"success": False, "error": str(e), "messages": [], "total_messages": 0, "context": {}}

    async def process_documents(self, data_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ ì²˜ë¦¬ ë° ì¸ë±ì‹±"""
        try:
            logger.info(f"ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {data_path}")

            # ë¬¸ì„œ ì²˜ë¦¬
            processed_docs = await self.document_processor.process_documents(data_path)

            if not processed_docs:
                return {"success": False, "message": "ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.", "processed_count": 0}

            # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
            success = await self.vector_store.add_documents(processed_docs)

            if success:
                # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
                await self.search_service.rebuild_index()

                # ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
                document_count = self.vector_store.get_document_count()
                self.system_monitor.update_initialization_status(
                    is_initialized=True, documents_loaded=document_count, search_index_built=True
                )

                logger.info(f"âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_docs)}ê°œ")
                return {
                    "success": True,
                    "message": f"{len(processed_docs)}ê°œ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "processed_count": len(processed_docs),
                }
            else:
                return {"success": False, "message": "ë¬¸ì„œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "processed_count": 0}

        except Exception as e:
            error_msg = f"ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self.system_monitor.record_error(error_msg, "document_processing")
            return {"success": False, "message": error_msg, "processed_count": 0}

    async def rebuild_indexes(self) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        try:
            logger.info("ğŸ”„ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹œì‘...")

            # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (HybridSearchServiceì˜ rebuild_index ë©”ì„œë“œ ì‚¬ìš©)
            await self.search_service.rebuild_index()

            # ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
            document_count = self.vector_store.get_document_count()
            self.system_monitor.update_initialization_status(
                is_initialized=True, documents_loaded=document_count, search_index_built=True
            )

            logger.info("âœ… ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ")
            return {"success": True, "message": "ì¸ë±ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤."}

        except Exception as e:
            error_msg = f"ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self.system_monitor.record_error(error_msg, "index_rebuild")
            return {"success": False, "message": error_msg}

    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        try:
            return self.system_monitor.get_system_status(self.vector_store)
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"status": "error", "message": str(e)}

    def get_service_statistics(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ"""
        try:
            return self.conversation_service.get_service_statistics()
        except Exception as e:
            logger.error(f"âŒ ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {"error": str(e)}

    async def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            logger.info("ğŸ§¹ RAG ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
            # í•„ìš”í•œ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
            logger.info("âœ… RAG ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {str(e)}")

    def _validate_configuration(self) -> bool:
        """ì„¤ì • ê²€ì¦"""
        try:
            required_settings = ["OPENAI_API_KEY", "EMBEDDING_MODEL", "TOP_K_DOCUMENTS", "SIMILARITY_THRESHOLD"]

            for setting in required_settings:
                if not hasattr(self.settings, setting):
                    logger.error(f"âŒ í•„ìˆ˜ ì„¤ì • ëˆ„ë½: {setting}")
                    return False

            return True

        except Exception as e:
            logger.error(f"âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            return False
