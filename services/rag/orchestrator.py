"""
RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
RAG ì‹œìŠ¤í…œì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°ìœ¨í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì¤‘ì•™ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
"""

import time
from typing import Dict, Any, List, Optional

from core.config import get_settings
from core.logging.config import get_logger
from services.document.processor import DocumentProcessor
from services.search.hybrid_search import HybridSearchService
from services.llm.openai_client import OpenAIService
from infrastructure.database.vector_store import VectorStore

# ë¡œê¹… ì„¤ì •
logger = get_logger(__name__)


class RAGOrchestrator:
    """
    RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    ëª¨ë“  RAG ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°ìœ¨í•˜ê³  ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì¤‘...")

            self.settings = get_settings()

            # ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.vector_store = VectorStore()
            self.document_processor = DocumentProcessor()
            self.llm_service = OpenAIService()
            self.search_service = HybridSearchService(self.vector_store)

            # ì‹œìŠ¤í…œ ìƒíƒœ
            self.is_initialized = False
            self.documents_loaded = False
            self.search_index_built = False

            logger.info("âœ… RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            raise

    async def initialize(self) -> bool:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ë¬¸ì„œ ë¡œë“œ"""
        try:
            if self.is_initialized:
                logger.info("â„¹ï¸ ì‹œìŠ¤í…œì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                return True

            logger.info("ğŸ“š ë²•ë¥  ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬ ì¤‘...")

            # 1. ë¬¸ì„œ ì²˜ë¦¬
            success = await self.document_processor.process_documents()
            if not success:
                logger.error("âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨")
                return False

            # 2. ë²¡í„° ìŠ¤í† ì–´ì— ë¬¸ì„œ ì¶”ê°€
            processed_chunks = self.document_processor.get_processed_chunks()
            if processed_chunks:
                vector_success = await self.vector_store.add_documents(processed_chunks)
                if not vector_success:
                    logger.error("âŒ ë²¡í„° DB êµ¬ì¶• ì‹¤íŒ¨")
                    return False
                self.documents_loaded = True

                # 3. ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶•
                logger.info("ğŸ”„ ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
                await self.search_service.build_indexes(processed_chunks)
                self.search_index_built = True
                logger.info("âœ… ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

            # 4. ì„¤ì • ê²€ì¦
            self._validate_configuration()

            self.is_initialized = True
            logger.info("ğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")

            # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
            self._log_system_info()

            return True

        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            return False

    async def process_query(self, user_query: str, user_id: Optional[str] = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬

        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            user_id: ì‚¬ìš©ì ID (ì„ íƒì‚¬í•­)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not self.is_initialized:
                return self._create_error_response("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

            start_time = time.time()
            logger.info(f"ğŸ” ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: '{user_query}' (ì‚¬ìš©ì: {user_id})")

            # 1. ì§ˆë¬¸ ë¶„ë¥˜ ë° ê²€ì¦
            logger.debug("ğŸ“‹ ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘...")
            classification = await self._classify_query(user_query)

            if not classification["is_legal"]:
                return self._create_response(
                    success=True,
                    answer="ì£„ì†¡í•©ë‹ˆë‹¤. ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë²•ë¥  ìƒë‹´ì´ í•„ìš”í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.",
                    confidence=0.0,
                    processing_time=time.time() - start_time,
                    classification=classification,
                    search_method="ë¶„ë¥˜ ë‹¨ê³„ì—ì„œ ì°¨ë‹¨",
                )

            # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
            logger.debug("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
            retrieved_docs = await self.search_service.search(
                query=user_query,
                top_k=self.settings.TOP_K_DOCUMENTS,
                similarity_threshold=self.settings.SIMILARITY_THRESHOLD,
            )

            if not retrieved_docs:
                return self._create_response(
                    success=True,
                    answer="ê´€ë ¨ëœ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ ì£¼ì„¸ìš”.",
                    confidence=0.0,
                    processing_time=time.time() - start_time,
                    classification=classification,
                    search_method="í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
                )

            # 3. LLMì„ í†µí•œ ë‹µë³€ ìƒì„±
            logger.debug("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
            response = await self.llm_service.generate_legal_response(user_query, retrieved_docs)

            processing_time = time.time() - start_time
            logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")

            return self._create_response(
                success=True,
                answer=response["answer"],
                confidence=response["confidence"],
                sources=self._format_sources(retrieved_docs),
                processing_time=processing_time,
                classification=classification,
                search_method="í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°)",
                retrieved_docs_count=len(retrieved_docs),
            )

        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return self._create_error_response(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        try:
            document_count = 0
            if self.documents_loaded:
                document_count = self.vector_store.get_document_count()

            return {
                "is_initialized": self.is_initialized,
                "documents_loaded": self.documents_loaded,
                "search_index_built": self.search_index_built,
                "document_count": document_count,
                "search_method": "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°)",
                "vector_db_path": self.settings.VECTOR_DB_PATH,
                "collection_name": self.settings.COLLECTION_NAME,
                "embedding_model": self.settings.EMBEDDING_MODEL,
                "llm_model": self.settings.OPENAI_MODEL,
                "top_k": self.settings.TOP_K_DOCUMENTS,
                "search_weights": {"bm25": self.settings.BM25_WEIGHT, "vector": self.settings.VECTOR_WEIGHT},
            }

        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {"is_initialized": False, "error": str(e)}

    async def rebuild_indexes(self, force_rebuild: bool = False) -> bool:
        """ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        try:
            logger.info("ğŸ”„ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹œì‘...")

            if not force_rebuild and self.is_initialized:
                logger.warning("âš ï¸ ì‹œìŠ¤í…œì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. force_rebuild=Trueë¡œ ê°•ì œ ì¬êµ¬ì¶•í•˜ì„¸ìš”.")
                return False

            # ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            self.documents_loaded = False
            self.search_index_built = False

            # ì¬ì´ˆê¸°í™”
            success = await self.initialize()

            if success:
                logger.info("âœ… ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ")
            else:
                logger.error("âŒ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨")

            return success

        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì˜¤ë¥˜: {str(e)}")
            return False

    # === ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤ ===

    async def _classify_query(self, query: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë¶„ë¥˜ (ì„ì‹œ êµ¬í˜„)"""
        # TODO: ì‹¤ì œ ë¶„ë¥˜ê¸° êµ¬í˜„
        return {"is_legal": True, "category": "general", "confidence": 0.8}

    def _validate_configuration(self) -> None:
        """ì„¤ì • ê²€ì¦"""
        # ê°€ì¤‘ì¹˜ í•©ê³„ ê²€ì¦ì€ ì´ë¯¸ settings.pyì—ì„œ ìˆ˜í–‰ë¨
        logger.debug("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")

    def _log_system_info(self) -> None:
        """ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…"""
        status = self.get_system_status()
        logger.info("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´:")
        logger.info(f"   - ë¬¸ì„œ ìˆ˜: {status.get('document_count', 0)}")
        logger.info(f"   - ê²€ìƒ‰ ë°©ë²•: {status.get('search_method', 'unknown')}")
        logger.info(f"   - ì„ë² ë”© ëª¨ë¸: {status.get('embedding_model', 'unknown')}")
        logger.info(f"   - LLM ëª¨ë¸: {status.get('llm_model', 'unknown')}")

    def _create_response(
        self,
        success: bool,
        answer: str,
        confidence: float = 0.0,
        sources: List[Dict] = None,
        processing_time: float = 0.0,
        classification: Dict = None,
        search_method: str = None,
        retrieved_docs_count: int = 0,
    ) -> Dict[str, Any]:
        """í‘œì¤€ ì‘ë‹µ ìƒì„±"""
        return {
            "success": success,
            "answer": answer,
            "confidence": confidence,
            "sources": sources or [],
            "processing_time": processing_time,
            "classification": classification,
            "search_method": search_method,
            "retrieved_docs_count": retrieved_docs_count,
        }

    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "success": False,
            "error": error_message,
            "answer": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "confidence": 0.0,
            "sources": [],
            "processing_time": 0.0,
        }

    def _format_sources(self, retrieved_docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì†ŒìŠ¤ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        sources = []
        for i, doc in enumerate(retrieved_docs):
            sources.append(
                {
                    "source": doc.get("source", f"ë¬¸ì„œ {i+1}"),
                    "content_preview": doc.get("content", "")[:200] + "...",
                    "hybrid_score": doc.get("hybrid_score", 0.0),
                    "bm25_score": doc.get("bm25_score", 0.0),
                    "vector_score": doc.get("vector_score", 0.0),
                }
            )
        return sources
